##################################################
## to be modified/checked for each experiment
##################################################

# number of training iterations
max_iter: 72
# QUESTION: how did we set this parameter to 24?
# ANSWER (use it for the assignment):
# 1. count the number of images in train.txt (384)
# 2. look inside the file train_val.protxt and chech the size of the mini-batches in train phase (32)
# 3. this means that each epoch of the mini-batch grandient descent (an epoch is a pass over all training images)
#    corresponds to 384/32=12 iterations
# 4. if we want to train for 4/6 epochs then we need to set <max_iter> to 4*12=48

# number of iterations to be performed at each validation step
test_iter: 3
# QUESTION: how did we set this parameter to 3?
# ANSWER (use it for the assignment):
# 1. count the number of images in  val.txt (96)
# 2. look inside the file train_val.protxt and chech the size of the mini-batches in the test (i.e. validation) phase (32)
# 3. this means that a pass over all validation images
#    corresponds to 96/32=3 iterations
# 4. if we want (clearly) to perform a single pass over the validation set at each validation step then <test_iter> will be 1*3=3

# carry out a validation step every <test_interval> training iterations
test_interval: 12
# we perform a validation step every epoch (i.e. every 12 iterations)

# display performance every <display> iterations
display: 12
# we display every epoch (i.e. every 12 iterations)

##################################################
## the following can be left as they are
##################################################

# relative path to the network definition
net: "train_val.prototxt"

# CPU/GPU mode
solver_mode: CPU

# save a snapshot every <snapshot> iterations
snapshot: 0
# we do not want to save intermediate snapshots

# the prefix of the name of the snapshot models (the suffix is the iteration number at which the model is saved)
snapshot_prefix: "icw"

# solver type
solver_type: SGD
momentum: 0.9

# L2 regularization
weight_decay: 0.0005

# learning rate decay policy
base_lr: 0.001
lr_policy: "poly"
power: 0.5

# NOTE: the currently implemented learning rate
# policies are:
#
#    - fixed: always return base_lr.
#    - step: return base_lr * gamma ^ (floor(iter / stepsize))
#    - exp: return base_lr * gamma ^ iter
#    - inv: return base_lr * (1 + gamma * iter) ^ (- power)
#    - multistep: similar to step but it allows non uniform steps defined by
#      stepvalue
#    - poly: the effective learning rate follows a polynomial decay, to be
#      zero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)
#    - sigmoid: the effective learning rate follows a sigmod decay
#      return base_lr ( 1/(1 + exp(-gamma * (iter - stepsize))))
#
# where base_lr, max_iter, gamma, stepsize, stepvalue and power are defined
# in the solver parameter protocol buffer, and iter is the current iteration.
